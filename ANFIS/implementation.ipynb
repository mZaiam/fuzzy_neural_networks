{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e6a8a41-6d91-4ab8-8845-31b9747b34cc",
   "metadata": {},
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4a621c-e114-4a87-9652-260daafd948f",
   "metadata": {},
   "source": [
    "The ANFIS implemented is based on a TSK inference system, that is, the rules are given in the form:\n",
    "\n",
    "\\begin{equation}\n",
    "R_i: x_1 \\text{ is } X^{(i)}_1 \\text{ and } \\cdots \\text{ and } x_n \\text{ is } X^{(i)}_n, \\text{ then } y_i = a^{(i)}_0 + \\sum_{j=1}^n a^{(i)}_jx_j.\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd6517f-6587-4085-a198-93543bae3914",
   "metadata": {},
   "source": [
    "The standard model starts with all possible rules of the form shown above, although there is an option to include initial rules. That is, given we have $n$ input variables, each one with a certain number of fuzzy sets defined in its universe of discourse, the total amount of initial rules is given by the product of all fuzzy sets. The model then select the rules via their activation strength. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bfdd13-faac-4f1d-bf9b-1871764e1e45",
   "metadata": {},
   "source": [
    "To define the information of the entries of the system, we will use a dictionary called `VARIABLES`. It has two keys:\n",
    "- `'inputs'`\n",
    "- `'outputs'`\n",
    "\n",
    "The values of these keys are a pair of variable and information, where the information of the variables is given by dictionaries. The information needed is:\n",
    "- `'n_sets'`: integer containing the number of fuzzy sets defined for that variable;\n",
    "- `'terms'`: list of strings representing the linguistic terms for each set fuzzy set of the variable (in ascending order, e.g., low, medium and high);\n",
    "- `'universe_of_discourse'`: list representing the limits of the interval where the variable is defined.\n",
    "\n",
    "The dictionary `VARIABLES` is given in the example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebeaac8-9a90-4141-a9ae-adf285e9ddcc",
   "metadata": {},
   "source": [
    "The weights are optimized after every training data the models predicts. The algorithm used is a fixed step gradient descent, and the error function used for the gradient calculation is the mean squared error, that is,\n",
    "\n",
    "\\begin{equation}\n",
    "E = \\frac{1}{2}(\\hat y - y)^2,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\hat y$ is the predicted value and $y$ is the actual value. From a TSK FRBS, we know that\n",
    "\n",
    "\\begin{equation}\n",
    "\\hat y = \\frac{\\sum w_iy_i}{\\sum w_i},\n",
    "\\end{equation}\n",
    "\n",
    "where $w_i$ is the firing strength from the $i$-th rule and $y_i$ is the output function of the $i$-th rule. As a convention, all functions here are of the form\n",
    "\n",
    "\\begin{equation}\n",
    "y_i = b_i + \\sum a_jx_j,\n",
    "\\end{equation}\n",
    "\n",
    "where $a_j$ and $b_i$ are coefficients of the function, and $x_j$ is the $j$-th input variable. Therefore, the partial derivatives of $E$ with respect to these coefficients are:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial E}{\\partial b_i} = (\\hat y - y) \\overline{w}_i \\text{ and } \\frac{\\partial E}{\\partial a_j} = (\\hat y - y) \\overline{w}_i x_j,\n",
    "\\end{equation}\n",
    "\n",
    "where $\\overline{w}_i$ is the normalized firing strength. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ilumpy",
   "language": "python",
   "name": "ilumpy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
